{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers.core import Dropout, Activation, Dense, Reshape, Flatten\n",
    "from keras.layers import concatenate\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "BATCHES_PER_EPOCH = 2000\n",
    "TRAIN_EPOCHS = 40\n",
    "VAL_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_labels():  \n",
    "    label_file = 'data/batches.meta.txt'\n",
    "    labels = []\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            labels.append(line.strip('\\n'))\n",
    "    labels = np.array(labels)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def read_data(phase='train'):\n",
    "    train_set_file = ['data/train/data_batch_{}.bin'.format(i) for i in range(1, 6)]\n",
    "    val_set_file = 'data/val/test_batch.bin'\n",
    "    if phase == 'train':\n",
    "        X = np.array([])\n",
    "        for tfile in train_set_file:\n",
    "            with open(tfile, 'rb') as f:\n",
    "                X = np.append(X, np.fromfile(f, dtype=np.uint8))\n",
    "        X = X.reshape(-1, 3073)\n",
    "        y = X[:, 0].reshape(-1, 1).astype(int)\n",
    "        X = X[:, 1:].reshape((-1, 3, 32, 32)).transpose((0, 2, 3, 1)) / 255\n",
    "    elif phase == 'val':\n",
    "        with open(val_set_file, 'rb') as f:\n",
    "            X = np.fromfile(f, dtype=np.uint8)\n",
    "        X = X.reshape(-1, 3073)\n",
    "        y = X[:, 0].reshape(-1, 1).astype(int)\n",
    "        X = X[:, 1:].reshape((-1, 3, 32, 32)).transpose((0, 2, 3, 1)) / 255\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    y = to_categorical(y, num_classes=None)\n",
    "    return X, y\n",
    "\n",
    "x_train, y_train = read_data()\n",
    "x_val, y_val = read_data('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_1             (None, 32, 32, 3) (None, 32, 32, 32)\n",
      "conv2d_2             (None, 32, 32, 32) (None, 32, 32, 32)\n",
      "max_pooling2d_1      (None, 32, 32, 32) (None, 16, 16, 32)\n",
      "conv2d_3             (None, 16, 16, 32) (None, 16, 16, 64)\n",
      "conv2d_4             (None, 16, 16, 64) (None, 16, 16, 64)\n",
      "max_pooling2d_2      (None, 16, 16, 64) (None, 8, 8, 64)\n",
      "conv2d_5             (None, 8, 8, 64) (None, 8, 8, 128)\n",
      "conv2d_6             (None, 8, 8, 128) (None, 8, 8, 128)\n",
      "max_pooling2d_3      (None, 8, 8, 128) (None, 4, 4, 128)\n",
      "conv2d_7             (None, 4, 4, 128) (None, 4, 4, 256)\n",
      "conv2d_8             (None, 4, 4, 256) (None, 4, 4, 256)\n",
      "max_pooling2d_4      (None, 4, 4, 256) (None, 2, 2, 256)\n",
      "flatten_1            (None, 2, 2, 256) (None, 1024)\n",
      "dense_1              (None, 1024) (None, 512)\n",
      "dropout_1            (None, 512) (None, 512)\n",
      "dense_2              (None, 512) (None, 512)\n",
      "dropout_2            (None, 512) (None, 512)\n",
      "dense_3              (None, 512) (None, 10)\n"
     ]
    }
   ],
   "source": [
    "def cnn_model(img_rows=32, img_cols=32):                      \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, 3, padding='same', activation='relu', input_shape=(img_rows, img_cols, 3)))\n",
    "    model.add(Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "\n",
    "    model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    \n",
    "    model.add(Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "\n",
    "    model.add(Conv2D(256, 3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, 3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        print('{:20s}'.format(layer.name), layer.input_shape, layer.output_shape)\n",
    "        \n",
    "    return model\n",
    "\n",
    "model = cnn_model()\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.1, decay=0.0005, momentum=0.9, nesterov=True)\n",
    "rmsprop = optimizers.RMSprop(lr=1e-4)\n",
    "\n",
    "model.compile(rmsprop, 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode='nearest',\n",
    "    rotation_range=10)\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
    "val_generator = val_datagen.flow(x_val, y_val, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "96s - loss: 2.1089 - acc: 0.2095 - val_loss: 1.8439 - val_acc: 0.3301\n",
      "Epoch 2/40\n",
      "95s - loss: 1.8611 - acc: 0.3127 - val_loss: 1.6522 - val_acc: 0.4055\n",
      "Epoch 3/40\n",
      "95s - loss: 1.6859 - acc: 0.3839 - val_loss: 1.4558 - val_acc: 0.4758\n",
      "Epoch 4/40\n",
      "95s - loss: 1.5551 - acc: 0.4347 - val_loss: 1.3172 - val_acc: 0.5195\n",
      "Epoch 5/40\n",
      "95s - loss: 1.4407 - acc: 0.4807 - val_loss: 1.2464 - val_acc: 0.5457\n",
      "Epoch 6/40\n",
      "95s - loss: 1.3426 - acc: 0.5194 - val_loss: 1.2154 - val_acc: 0.5478\n",
      "Epoch 7/40\n",
      "95s - loss: 1.2545 - acc: 0.5525 - val_loss: 1.0385 - val_acc: 0.6320\n",
      "Epoch 8/40\n",
      "95s - loss: 1.1751 - acc: 0.5844 - val_loss: 1.0429 - val_acc: 0.6250\n",
      "Epoch 9/40\n",
      "95s - loss: 1.1038 - acc: 0.6116 - val_loss: 0.9575 - val_acc: 0.6708\n",
      "Epoch 10/40\n",
      "95s - loss: 1.0359 - acc: 0.6372 - val_loss: 1.0240 - val_acc: 0.6359\n",
      "Epoch 11/40\n",
      "95s - loss: 0.9748 - acc: 0.6600 - val_loss: 1.0083 - val_acc: 0.6590\n",
      "Epoch 12/40\n",
      "95s - loss: 0.9185 - acc: 0.6800 - val_loss: 0.8346 - val_acc: 0.7051\n",
      "Epoch 13/40\n",
      "95s - loss: 0.8674 - acc: 0.6985 - val_loss: 0.8065 - val_acc: 0.7324\n",
      "Epoch 14/40\n",
      "95s - loss: 0.8205 - acc: 0.7146 - val_loss: 0.7410 - val_acc: 0.7386\n",
      "Epoch 15/40\n",
      "95s - loss: 0.7822 - acc: 0.7298 - val_loss: 0.7193 - val_acc: 0.7598\n",
      "Epoch 16/40\n",
      "95s - loss: 0.7464 - acc: 0.7426 - val_loss: 0.7924 - val_acc: 0.7336\n",
      "Epoch 17/40\n",
      "95s - loss: 0.7114 - acc: 0.7547 - val_loss: 0.6865 - val_acc: 0.7733\n",
      "Epoch 18/40\n",
      "95s - loss: 0.6794 - acc: 0.7661 - val_loss: 0.6503 - val_acc: 0.7812\n",
      "Epoch 19/40\n",
      "95s - loss: 0.6511 - acc: 0.7762 - val_loss: 0.7331 - val_acc: 0.7512\n",
      "Epoch 20/40\n",
      "95s - loss: 0.6274 - acc: 0.7840 - val_loss: 0.6015 - val_acc: 0.7958\n",
      "Epoch 21/40\n",
      "95s - loss: 0.6032 - acc: 0.7928 - val_loss: 0.6213 - val_acc: 0.7937\n",
      "Epoch 22/40\n",
      "95s - loss: 0.5868 - acc: 0.7994 - val_loss: 0.6219 - val_acc: 0.7895\n",
      "Epoch 23/40\n",
      "95s - loss: 0.5640 - acc: 0.8066 - val_loss: 0.6274 - val_acc: 0.7863\n",
      "Epoch 24/40\n",
      "95s - loss: 0.5503 - acc: 0.8123 - val_loss: 0.6552 - val_acc: 0.7820\n",
      "Epoch 25/40\n",
      "95s - loss: 0.5332 - acc: 0.8182 - val_loss: 0.5793 - val_acc: 0.8064\n",
      "Epoch 26/40\n",
      "95s - loss: 0.5208 - acc: 0.8231 - val_loss: 0.5552 - val_acc: 0.8160\n",
      "Epoch 27/40\n",
      "95s - loss: 0.5069 - acc: 0.8271 - val_loss: 0.6580 - val_acc: 0.7910\n",
      "Epoch 28/40\n",
      "95s - loss: 0.4996 - acc: 0.8304 - val_loss: 0.6376 - val_acc: 0.7974\n",
      "Epoch 29/40\n",
      "95s - loss: 0.4880 - acc: 0.8349 - val_loss: 0.6074 - val_acc: 0.8098\n",
      "Epoch 30/40\n",
      "95s - loss: 0.4815 - acc: 0.8368 - val_loss: 0.6217 - val_acc: 0.8082\n",
      "Epoch 31/40\n",
      "95s - loss: 0.4774 - acc: 0.8391 - val_loss: 0.5768 - val_acc: 0.8264\n",
      "Epoch 32/40\n",
      "95s - loss: 0.4727 - acc: 0.8396 - val_loss: 0.6277 - val_acc: 0.8105\n",
      "Epoch 33/40\n",
      "95s - loss: 0.4714 - acc: 0.8416 - val_loss: 0.5333 - val_acc: 0.8254\n",
      "Epoch 34/40\n",
      "95s - loss: 0.4693 - acc: 0.8425 - val_loss: 0.6753 - val_acc: 0.7937\n",
      "Epoch 35/40\n",
      "95s - loss: 0.4672 - acc: 0.8432 - val_loss: 0.6018 - val_acc: 0.8148\n",
      "Epoch 36/40\n",
      "95s - loss: 0.4677 - acc: 0.8442 - val_loss: 0.6056 - val_acc: 0.8109\n",
      "Epoch 37/40\n",
      "95s - loss: 0.4668 - acc: 0.8441 - val_loss: 0.6964 - val_acc: 0.7984\n",
      "Epoch 38/40\n",
      "95s - loss: 0.4676 - acc: 0.8435 - val_loss: 0.6124 - val_acc: 0.8172\n",
      "Epoch 39/40\n",
      "95s - loss: 0.4709 - acc: 0.8435 - val_loss: 0.5782 - val_acc: 0.8186\n",
      "Epoch 40/40\n",
      "95s - loss: 0.4735 - acc: 0.8432 - val_loss: 0.6350 - val_acc: 0.8254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fee72648358>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb = TensorBoard('data/logs')\n",
    "cp = ModelCheckpoint('data/weights.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "\n",
    "model.fit_generator(train_generator, BATCHES_PER_EPOCH, TRAIN_EPOCHS,\n",
    "                    validation_data=val_generator, validation_steps=VAL_EPOCHS,\n",
    "                    verbose=2, callbacks=[tb, cp], initial_epoch=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
